{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exciting-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sublime-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "imdb_data=pd.read_csv('../../data/IMDB_reviews.csv')\n",
    "\n",
    "# print(imdb_data.shape,'\\n')\n",
    "# print(imdb_data.head(10),'\\n')\n",
    "# print(imdb_data['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-colonial",
   "metadata": {},
   "source": [
    "### Step 1 - Preprocessing Text to tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "institutional-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.tokenize.toktok import ToktokTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "british-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing text data\n",
    "\n",
    "def preprocessing(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    text = soup.get_text()     # Step 1 - Remove html tags\n",
    "    pattern = r'[^a-zA-z0-9\\s]' \n",
    "    text = re.sub(pattern,'',text)   # Step 2 - Remove punctuation\n",
    "    text = text.lower()     # Step 3 - Make text lowercase\n",
    "    tokenizer=ToktokTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)    # Step 4 - Tokenizing\n",
    "    ps=nltk.porter.PorterStemmer()    # Step 5 - Stemming\n",
    "    stopword_list=nltk.corpus.stopwords.words('english')\n",
    "    stop=set(stopwords.words('english'))\n",
    "    filtered_tokens = [ps.stem(word).strip() for word in tokens if word not in stopword_list]    # Step 6 - Removing stopwords\n",
    "    return filtered_tokens\n",
    "#Apply function on review column\n",
    "imdb_data['review']=imdb_data['review'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ambient-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data.to_csv('IMDB_reviews_preprocessed.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-dayton",
   "metadata": {},
   "source": [
    "### Step 2 - Tokens to features and train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acute-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = pd.read_csv('IMDB_reviews_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "posted-ticket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['one', 'review', 'mention', 'watch', '1', 'oz...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['wonder', 'littl', 'product', 'film', 'techni...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['thought', 'wonder', 'way', 'spend', 'time', ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['basic', 'there', 'famili', 'littl', 'boy', '...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['petter', 'mattei', 'love', 'time', 'money', ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>['thought', 'movi', 'right', 'good', 'job', 'w...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>['bad', 'plot', 'bad', 'dialogu', 'bad', 'act'...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>['cathol', 'taught', 'parochi', 'elementari', ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>['im', 'go', 'disagre', 'previou', 'comment', ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>['one', 'expect', 'star', 'trek', 'movi', 'hig...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      ['one', 'review', 'mention', 'watch', '1', 'oz...  positive\n",
       "1      ['wonder', 'littl', 'product', 'film', 'techni...  positive\n",
       "2      ['thought', 'wonder', 'way', 'spend', 'time', ...  positive\n",
       "3      ['basic', 'there', 'famili', 'littl', 'boy', '...  negative\n",
       "4      ['petter', 'mattei', 'love', 'time', 'money', ...  positive\n",
       "...                                                  ...       ...\n",
       "49995  ['thought', 'movi', 'right', 'good', 'job', 'w...  positive\n",
       "49996  ['bad', 'plot', 'bad', 'dialogu', 'bad', 'act'...  negative\n",
       "49997  ['cathol', 'taught', 'parochi', 'elementari', ...  negative\n",
       "49998  ['im', 'go', 'disagre', 'previou', 'comment', ...  negative\n",
       "49999  ['one', 'expect', 'star', 'trek', 'movi', 'hig...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "latin-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_train_reviews=imdb_data.review[:40000]\n",
    "norm_test_reviews=imdb_data.review[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bigger-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "cv = CountVectorizer(\n",
    "        tokenizer=dummy,\n",
    "        preprocessor=dummy\n",
    "    )  \n",
    "# #Count vectorizer for bag of words\n",
    "# cv=CountVectorizer(tokenizer=None,ngram_range=(1,3))\n",
    "#transformed train reviews\n",
    "cv_train_reviews=cv.fit_transform(norm_train_reviews)\n",
    "cv_test_reviews=cv.transform(norm_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "affiliated-recorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "#labeling the sentiment data\n",
    "lb=LabelBinarizer()\n",
    "#transformed sentiment data\n",
    "sentiment_data=lb.fit_transform(imdb_data['sentiment'])\n",
    "print(sentiment_data.shape)\n",
    "#Spliting the sentiment data\n",
    "train_sentiments=sentiment_data[:40000]\n",
    "test_sentiments=sentiment_data[40000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-camping",
   "metadata": {},
   "source": [
    "### Step 3 - Fit and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "apparent-museum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "lr=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n",
    "#Fitting the model for Bag of words\n",
    "lr_bow=lr.fit(cv_train_reviews,train_sentiments)\n",
    "print(lr_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "whole-jurisdiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "#Predicting the model for bag of words\n",
    "lr_bow_predict=lr.predict(cv_test_reviews)\n",
    "print(lr_bow_predict)\n",
    "# ##Predicting the model for tfidf features\n",
    "# lr_tfidf_predict=lr.predict(tv_test_reviews)\n",
    "# print(lr_tfidf_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-given",
   "metadata": {},
   "source": [
    "### Step 4 - Metrics Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "mature-tribune",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_bow_score : 0.8851\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score for bag of words\n",
    "lr_bow_score=accuracy_score(test_sentiments,lr_bow_predict)\n",
    "print(\"lr_bow_score :\",lr_bow_score)\n",
    "\n",
    "# #Accuracy score for tfidf features\n",
    "# lr_tfidf_score=accuracy_score(test_sentiments,lr_tfidf_predict)\n",
    "# print(\"lr_tfidf_score :\",lr_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "greek-tongue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.89      0.88      0.88      4993\n",
      "    Negative       0.88      0.89      0.89      5007\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for bag of words \n",
    "lr_bow_report=classification_report(test_sentiments,lr_bow_predict,target_names=['Positive','Negative'])\n",
    "print(lr_bow_report)\n",
    "\n",
    "# #Classification report for tfidf features\n",
    "# lr_tfidf_report=classification_report(test_sentiments,lr_tfidf_predict,target_names=['Positive','Negative'])\n",
    "# print(lr_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "little-emperor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4442  565]\n",
      " [ 584 4409]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for bag of words\n",
    "cm_bow=confusion_matrix(test_sentiments,lr_bow_predict,labels=[1,0])\n",
    "print(cm_bow)\n",
    "\n",
    "# #confusion matrix for tfidf features\n",
    "# cm_tfidf=confusion_matrix(test_sentiments,lr_tfidf_predict,labels=[1,0])\n",
    "# print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adjustable-strengthening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "mnb=MultinomialNB()\n",
    "#fitting the svm for bag of words\n",
    "mnb_bow=mnb.fit(cv_train_reviews,train_sentiments)\n",
    "print(mnb_bow)\n",
    "# #fitting the svm for tfidf features\n",
    "# mnb_tfidf=mnb.fit(tv_train_reviews,train_sentiments)\n",
    "# print(mnb_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "portuguese-search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "#Predicting the model for bag of words\n",
    "mnb_bow_predict=mnb.predict(cv_test_reviews)\n",
    "print(mnb_bow_predict)\n",
    "# #Predicting the model for tfidf features\n",
    "# mnb_tfidf_predict=mnb.predict(tv_test_reviews)\n",
    "# print(mnb_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "twenty-mobility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb_bow_score : 0.8568\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score for bag of words\n",
    "mnb_bow_score=accuracy_score(test_sentiments,mnb_bow_predict)\n",
    "print(\"mnb_bow_score :\",mnb_bow_score)\n",
    "# #Accuracy score for tfidf features\n",
    "# mnb_tfidf_score=accuracy_score(test_sentiments,mnb_tfidf_predict)\n",
    "# print(\"mnb_tfidf_score :\",mnb_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "perceived-inspector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.84      0.88      0.86      4993\n",
      "    Negative       0.87      0.84      0.85      5007\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for bag of words \n",
    "mnb_bow_report=classification_report(test_sentiments,mnb_bow_predict,target_names=['Positive','Negative'])\n",
    "print(mnb_bow_report)\n",
    "# #Classification report for tfidf features\n",
    "# mnb_tfidf_report=classification_report(test_sentiments,mnb_tfidf_predict,target_names=['Positive','Negative'])\n",
    "# print(mnb_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "excellent-disposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4192  815]\n",
      " [ 617 4376]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for bag of words\n",
    "cm_bow=confusion_matrix(test_sentiments,mnb_bow_predict,labels=[1,0])\n",
    "print(cm_bow)\n",
    "# #confusion matrix for tfidf features\n",
    "# cm_tfidf=confusion_matrix(test_sentiments,mnb_tfidf_predict,labels=[1,0])\n",
    "# print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-nursing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

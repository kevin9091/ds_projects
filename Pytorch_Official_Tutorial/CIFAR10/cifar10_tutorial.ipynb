{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.BN1 = nn.BatchNorm2d(16) \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.BN2 = nn.BatchNorm1d(120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.pool(self.conv1(x)))\n",
    "        x = self.BN1(F.relu(self.pool(self.conv2(x))))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = self.BN2(F.relu(self.fc1(x)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=False, transform=transform)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def imshow(img):\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "#     npimg = img.numpy()\n",
    "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "#     plt.show()\n",
    "\n",
    "# # get some random training images\n",
    "# dataiter = iter(trainloader)\n",
    "# images, labels = dataiter.next()\n",
    "\n",
    "# # show images\n",
    "# imshow(torchvision.utils.make_grid(images))\n",
    "# # print labels\n",
    "# print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-87487b7bbf03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m optims = {'Momentum_SGD': optim.SGD(net.parameters(), lr=lr), \n\u001b[0m\u001b[0;32m      6\u001b[0m              'ADAM': optim.Adam(net.parameters(), lr=lr)}\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "### Hyperparameters\n",
    "\n",
    "shuffle=True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "optims = {'Momentum_SGD': optim.SGD(net.parameters(), lr=lr), \n",
    "             'ADAM': optim.Adam(net.parameters(), lr=lr)}\n",
    "\n",
    "parameters = OrderedDict(\n",
    "batch_size=[100],\n",
    "lr = [0.01],\n",
    "# optimiser = list(optims.keys())\n",
    ")\n",
    "\n",
    "param_values = [v for v in parameters.values()]\n",
    "print(param_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar10 batch_size=100 lr=0.01 optimizer=ADAM\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    weight_decay: 0\n",
      ")\n",
      "[1,   100] loss: 1.762\n",
      "[1,   200] loss: 1.521\n",
      "[1,   300] loss: 1.443\n",
      "[1,   400] loss: 1.355\n",
      "[1,   500] loss: 1.347\n",
      "[2,   100] loss: 1.266\n",
      "[2,   200] loss: 1.264\n",
      "[2,   300] loss: 1.202\n",
      "[2,   400] loss: 1.181\n",
      "[2,   500] loss: 1.176\n",
      "At the end of epoch 2\n",
      "Accuracy of the network on the 60000 train images: 59 %\n",
      "Accuracy of the network on the 10000 test images: 59 %\n",
      "Finished Training\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for batch_size, lr in product(*param_values):\n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=shuffle, num_workers=2)\n",
    "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    net = Net().to(device)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "#     optimizer = optims[optimiser]\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    comment = f'cifar10 batch_size={batch_size} lr={lr} optimizer={optimiser}'\n",
    "    print(comment)\n",
    "    print(optimizer)\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "    tb_count=0\n",
    "\n",
    "    for epoch in range(2): \n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:   \n",
    "                tb_count += 1\n",
    "                tb.add_scalar('Running Loss', running_loss/100, tb_count)\n",
    "                print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        if epoch % 2 == 1:\n",
    "            print('At the end of epoch %d' %(epoch+1))\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for data in trainloader:\n",
    "                    images, labels = data[0].to(device), data[1].to(device)\n",
    "                    outputs = net(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            tb.add_scalar('Train Accuracy', 100 * correct / total, epoch+1)\n",
    "            print('Accuracy of the network on the 60000 train images: %d %%' % (100 * correct / total))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for data in testloader:\n",
    "                    images, labels = data[0].to(device), data[1].to(device)\n",
    "                    outputs = net(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            tb.add_scalar('Test Accuracy', 100 * correct / total, epoch+1)\n",
    "            print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "    tb.close()\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for data in trainloader:\n",
    "#         images, labels = data[0].to(device), data[1].to(device)\n",
    "#         outputs = net(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print('Accuracy of the network on the 60000 train images: %d %%' % (\n",
    "#     100 * correct / total))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for data in testloader:\n",
    "#         images, labels = data[0].to(device), data[1].to(device)\n",
    "#         outputs = net(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "#     100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_correct = list(0. for i in range(10))\n",
    "# class_total = list(0. for i in range(10))\n",
    "# with torch.no_grad():\n",
    "#     for data in testloader:\n",
    "#         images, labels = data[0].to(device), data[1].to(device)\n",
    "#         outputs = net(images)\n",
    "#         _, predicted = torch.max(outputs, 1)\n",
    "#         c = (predicted == labels).squeeze()\n",
    "#         for i in range(100):\n",
    "#             label = labels[i]\n",
    "#             class_correct[label] += c[i].item()\n",
    "#             class_total[label] += 1\n",
    "\n",
    "\n",
    "# for i in range(10):\n",
    "#     print('Accuracy of %5s : %2d %%' % (\n",
    "#         classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = './cifar_net.pth'\n",
    "# torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = Net()\n",
    "# net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(testloader)\n",
    "# images, labels = dataiter.next()\n",
    "\n",
    "# # print images\n",
    "# imshow(torchvision.utils.make_grid(images[:4]))\n",
    "# print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = net(images)\n",
    "# _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "#                               for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

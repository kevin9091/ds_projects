{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code has been borrowed from https://www.kaggle.com/abhishek/melanoma-detection-with-pytorch. Thanks to Abhishek!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import model_selection\n",
    "from itertools import product\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from wtfml.data_loaders.image import ClassificationLoader\n",
    "import albumentations\n",
    "\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Pytorch Train, Test and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 5 stratified k-folds in training set\n",
    "melanoma_path=\"../../data/melanoma/\"\n",
    "melanoma_image_path=\"../../data/melanoma/\"\n",
    "\n",
    "df = pd.read_csv(melanoma_path + \"train.csv\")\n",
    "df[\"kfold\"] = -1    \n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "y = df.target.values\n",
    "kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "for f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n",
    "    df.loc[v_, 'kfold'] = f\n",
    "\n",
    "# Create train and validation indices\n",
    "df_train = df[df.kfold != 0].reset_index(drop=True)\n",
    "df_valid = df[df.kfold == 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path=melanoma_image_path + \"train/\"\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_images = df_train.image_name.values.tolist()\n",
    "train_images = [os.path.join(training_data_path, i + \".png\") for i in train_images]\n",
    "train_targets = df_train.target.values\n",
    "\n",
    "train_aug = albumentations.Compose([\n",
    "    albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),\n",
    "#     albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15),\n",
    "#     albumentations.Flip(p=0.5)\n",
    "])\n",
    "\n",
    "train_dataset = ClassificationLoader(\n",
    "    image_paths=train_images,\n",
    "    targets=train_targets,\n",
    "    resize=None,\n",
    "    augmentations=train_aug,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_images = df_valid.image_name.values.tolist()\n",
    "valid_images = [os.path.join(training_data_path, i + \".png\") for i in valid_images]\n",
    "valid_targets = df_valid.target.values\n",
    "\n",
    "valid_aug = albumentations.Compose([\n",
    "    albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n",
    "])\n",
    "\n",
    "valid_dataset = ClassificationLoader(\n",
    "    image_paths=valid_images,\n",
    "    targets=valid_targets,\n",
    "    resize=None,\n",
    "    augmentations=valid_aug,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = melanoma_image_path + \"test/\"\n",
    "df_test = pd.read_csv(melanoma_path + \"test.csv\")\n",
    "\n",
    "test_aug = albumentations.Compose([\n",
    "        albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n",
    "])\n",
    "\n",
    "test_images = df_test.image_name.values.tolist()\n",
    "test_images = [os.path.join(test_data_path, i + \".png\") for i in test_images]\n",
    "test_targets = np.zeros(len(test_images))\n",
    "\n",
    "test_dataset = ClassificationLoader(\n",
    "    image_paths=test_images,\n",
    "    targets=test_targets,\n",
    "    resize=None,\n",
    "    augmentations=test_aug,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=9, padding=4)\n",
    "        self.conv3 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=7, padding=3)\n",
    "        self.conv5 = nn.Conv2d(in_channels=12, out_channels=18, kernel_size=5, padding=2)\n",
    "#         self.conv2 = nn.Conv2d(in_channels=6, out_channels=9, kernel_size=7, padding=3)\n",
    "#         self.conv4 = nn.Conv2d(in_channels=12, out_channels=15, kernel_size=5, padding=2)\n",
    "#         self.conv6 = nn.Conv2d(in_channels=18, out_channels=24, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=4, stride=4)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(in_features=18*7*7, out_features=100)\n",
    "        self.fc2 = nn.Linear(in_features=100, out_features=20)\n",
    "        self.out = nn.Linear(in_features=20, out_features=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.pool1(self.conv1(x)))  # Layer 1\n",
    "        x = F.relu(self.pool1(self.conv3(x)))  # Layer 2\n",
    "        x = F.relu(self.pool2(self.conv5(x)))  # Layer 3\n",
    "        x = x.reshape(-1, 18*7*7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focal Loss Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "[[100], [0.01]]\n"
     ]
    }
   ],
   "source": [
    "shuffle=True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "parameters = OrderedDict(\n",
    "    batch_size=[100],\n",
    "    lr = [0.01],\n",
    ")\n",
    "\n",
    "param_values = [v for v in parameters.values()]\n",
    "print(param_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "melanoma batch_size=100 lr=0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-fa4f8a076b4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'targets'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    574\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[1;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mpoll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    328\u001b[0m                         _winapi.PeekNamedPipe(self._handle)[0] != 0):\n\u001b[0;32m    329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_get_more_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    866\u001b[0m                         \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mready_handles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_exhaustive_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwaithandle_to_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m             \u001b[1;31m# request that overlapped reads stop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    798\u001b[0m         \u001b[0mready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_winapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWaitForMultipleObjects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mWAIT_TIMEOUT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "for batch_size, lr in product(*param_values):\n",
    "    \n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "#     trainloader = DataLoader(dataset, batch_size=batch_size, num_workers=2, sampler = train_sampler)\n",
    "#     testloader = DataLoader(dataset, batch_size=batch_size, num_workers=2, sampler = valid_sampler)\n",
    "\n",
    "    net = Net().to(device)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "#     criterion = nn.BCEWithLogitsLoss()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    comment = f'melanoma batch_size={batch_size} lr={lr}'\n",
    "    print(comment)\n",
    "#     tb = SummaryWriter(comment=comment)\n",
    "#     tb_count=0\n",
    "\n",
    "    for epoch in range(4): \n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data['image'].to(device), data['targets'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 50 == 49:   \n",
    "#                 tb_count += 1\n",
    "#                 tb.add_scalar('Running Loss', running_loss/100, tb_count)\n",
    "                print('[%d, %5d] loss: %.5f' %(epoch + 1, i + 1, running_loss / 50))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        if epoch % 2 == 1:\n",
    "            print('At the end of epoch %d' %(epoch+1))\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                preds=[]\n",
    "                targets=[]\n",
    "                for data in train_loader:\n",
    "                    images, labels = data['image'].to(device), data['targets'].to(device)\n",
    "                    outputs = net(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    preds += list(predicted.cpu().detach().numpy().squeeze())\n",
    "                    targets += list(labels.cpu().detach().numpy().squeeze())\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "    #             tb.add_scalar('Train Accuracy', 100 * correct / total, epoch+1)\n",
    "            print('Accuracy of the network on the train images: %d %%' % (100 * correct / total))\n",
    "            print('Training Confusion Matrix:')\n",
    "            print(confusion_matrix(targets, preds))\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                preds=[]\n",
    "                targets=[]\n",
    "                for data in valid_loader:\n",
    "                    images, labels = data['image'].to(device), data['targets'].to(device)\n",
    "                    outputs = net(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    preds += list(predicted.cpu().detach().numpy().squeeze())\n",
    "                    targets += list(labels.cpu().detach().numpy().squeeze())\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "    #             tb.add_scalar('Test Accuracy', 100 * correct / total, epoch+1)\n",
    "            print('Accuracy of the network on the validation images: %d %%' % (100 * correct / total))\n",
    "            print('Validation Confusion Matrix:')\n",
    "            print(confusion_matrix(targets, preds))\n",
    "\n",
    "#     tb.close()\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the train images: 98 %\n",
      "26500 26500\n",
      "Training Confusion Matrix:\n",
      "[[26033     0]\n",
      " [  467     0]]\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=200, shuffle=False, num_workers=4)\n",
    "with torch.no_grad():\n",
    "    preds=[]\n",
    "    targets=[]\n",
    "    for data in train_loader:\n",
    "        images, labels = data['image'].to(device), data['targets'].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        preds += list(predicted.cpu().detach().numpy().squeeze())\n",
    "        targets += list(labels.cpu().detach().numpy().squeeze())\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# tb.add_scalar('Train Accuracy', 100 * correct / total, epoch+1)\n",
    "print('Accuracy of the network on the train images: %d %%' % (100 * correct / total))\n",
    "print(len(preds), len(targets))\n",
    "print('Training Confusion Matrix:')\n",
    "print(confusion_matrix(targets, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0], device='cuda:0')\n",
      "tensor([[ 1.6251, -1.5650],\n",
      "        [ 2.4110, -2.4205],\n",
      "        [ 2.1758, -2.2124],\n",
      "        [ 2.5531, -2.6598],\n",
      "        [ 1.9343, -1.9504],\n",
      "        [ 1.4695, -1.4132],\n",
      "        [ 1.7398, -1.7218],\n",
      "        [ 2.3768, -2.3472],\n",
      "        [ 2.3603, -2.4383],\n",
      "        [ 1.9497, -1.9666],\n",
      "        [ 2.2039, -2.1927],\n",
      "        [ 1.9358, -1.9502],\n",
      "        [ 1.9990, -2.0269],\n",
      "        [ 2.6702, -2.7940],\n",
      "        [ 1.7008, -1.6948],\n",
      "        [ 2.6111, -2.7261],\n",
      "        [ 2.2365, -2.2746],\n",
      "        [ 2.0024, -2.0147],\n",
      "        [ 1.8776, -1.8986],\n",
      "        [ 2.4188, -2.4925],\n",
      "        [ 1.6751, -1.6623],\n",
      "        [ 2.2536, -2.3019],\n",
      "        [ 2.6970, -2.8251],\n",
      "        [ 2.1310, -2.1765],\n",
      "        [ 2.5030, -2.6018],\n",
      "        [ 2.3791, -2.4513],\n",
      "        [ 2.4122, -2.4980],\n",
      "        [ 1.0554, -0.8762],\n",
      "        [ 1.8266, -1.7225],\n",
      "        [ 2.7110, -2.8412],\n",
      "        [ 2.6095, -2.5780],\n",
      "        [ 2.0534, -2.0881],\n",
      "        [ 2.2362, -2.2821],\n",
      "        [ 2.3937, -2.4727],\n",
      "        [ 1.6002, -1.5655],\n",
      "        [ 2.0286, -2.0530],\n",
      "        [ 1.7139, -1.7037],\n",
      "        [ 2.4416, -2.4105],\n",
      "        [ 2.0086, -2.0187],\n",
      "        [ 1.8178, -1.8217],\n",
      "        [ 1.9493, -1.9137],\n",
      "        [ 1.5652, -1.5409],\n",
      "        [ 1.9177, -1.9279],\n",
      "        [ 1.8644, -1.8894],\n",
      "        [ 2.8666, -2.9394],\n",
      "        [ 1.6127, -1.5790],\n",
      "        [ 1.8864, -1.8287],\n",
      "        [ 2.4913, -2.5870],\n",
      "        [ 1.8573, -1.8375],\n",
      "        [ 2.1848, -2.2342],\n",
      "        [ 1.6886, -1.6661],\n",
      "        [ 1.9040, -1.9157],\n",
      "        [ 1.2284, -1.1443],\n",
      "        [ 2.0354, -2.0628],\n",
      "        [ 2.3495, -2.4267],\n",
      "        [ 2.0309, -2.0592],\n",
      "        [ 2.5778, -2.6897],\n",
      "        [ 2.3562, -2.4338],\n",
      "        [ 1.3877, -1.3329],\n",
      "        [ 1.5891, -1.5531],\n",
      "        [ 2.3819, -2.4616],\n",
      "        [ 1.3571, -1.2886],\n",
      "        [ 1.7711, -1.7696],\n",
      "        [ 2.5450, -2.6504],\n",
      "        [ 1.7719, -1.7469],\n",
      "        [ 2.4860, -2.5856],\n",
      "        [ 2.1377, -2.1823],\n",
      "        [ 2.4013, -2.4212],\n",
      "        [ 2.4950, -2.5938],\n",
      "        [ 1.4899, -1.4621],\n",
      "        [ 1.9100, -1.9230],\n",
      "        [ 2.4527, -2.5437],\n",
      "        [ 1.8751, -1.8616],\n",
      "        [ 1.9978, -1.9443],\n",
      "        [ 2.4721, -2.5664],\n",
      "        [ 2.1304, -2.1553],\n",
      "        [ 1.9881, -2.0082],\n",
      "        [ 1.6426, -1.5873],\n",
      "        [ 2.5829, -2.6942],\n",
      "        [ 2.5359, -2.5954],\n",
      "        [ 2.5928, -2.7069],\n",
      "        [ 2.3690, -2.4485],\n",
      "        [ 1.8804, -1.8889],\n",
      "        [ 2.2709, -2.3385],\n",
      "        [ 2.6163, -2.7332],\n",
      "        [ 2.4173, -2.5029],\n",
      "        [ 1.3477, -1.2740],\n",
      "        [ 1.6492, -1.5421],\n",
      "        [ 2.2832, -2.3537],\n",
      "        [ 2.0922, -2.1127],\n",
      "        [ 2.5660, -2.6747],\n",
      "        [ 2.5513, -2.6579],\n",
      "        [ 1.8291, -1.8117],\n",
      "        [ 2.4548, -2.5489],\n",
      "        [ 1.7523, -1.6652],\n",
      "        [ 1.3108, -1.2087],\n",
      "        [ 2.3591, -2.4376],\n",
      "        [ 1.8875, -1.8991],\n",
      "        [ 2.4235, -2.5110],\n",
      "        [ 1.5085, -1.4091]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0], device='cuda:0')\n",
      "tensor([[ 1.6281, -1.5976],\n",
      "        [ 2.5636, -2.6724],\n",
      "        [ 2.5367, -2.6422],\n",
      "        [ 2.1985, -2.2532],\n",
      "        [ 1.7959, -1.7942],\n",
      "        [ 1.6870, -1.5878],\n",
      "        [ 1.4577, -1.4346],\n",
      "        [ 2.4835, -2.5822],\n",
      "        [ 2.6741, -2.7992],\n",
      "        [ 1.8723, -1.8788],\n",
      "        [ 1.9932, -1.8894],\n",
      "        [ 2.4683, -2.5594],\n",
      "        [ 2.0440, -2.0774],\n",
      "        [ 1.4403, -1.3768],\n",
      "        [ 1.3062, -1.2191],\n",
      "        [ 1.5003, -1.3658],\n",
      "        [ 1.8808, -1.8877],\n",
      "        [ 2.6079, -2.7226],\n",
      "        [ 1.8025, -1.7958],\n",
      "        [ 1.7900, -1.7720],\n",
      "        [ 2.5114, -2.6147],\n",
      "        [ 1.9096, -1.9227],\n",
      "        [ 1.8810, -1.8787],\n",
      "        [ 1.9283, -1.9142],\n",
      "        [ 2.4911, -2.5893],\n",
      "        [ 2.6080, -2.7235],\n",
      "        [ 1.3409, -1.2648],\n",
      "        [ 2.6193, -2.7369],\n",
      "        [ 1.7296, -1.7129],\n",
      "        [ 2.6537, -2.7741],\n",
      "        [ 2.2676, -2.3324],\n",
      "        [ 1.5212, -1.4616],\n",
      "        [ 1.7881, -1.7972],\n",
      "        [ 1.9691, -1.9806],\n",
      "        [ 1.6553, -1.6367],\n",
      "        [ 2.2021, -2.1698],\n",
      "        [ 2.0086, -2.0348],\n",
      "        [ 2.4875, -2.5851],\n",
      "        [ 1.7654, -1.7407],\n",
      "        [ 2.2575, -2.3191],\n",
      "        [ 2.4860, -2.5829],\n",
      "        [ 1.1429, -0.9057],\n",
      "        [ 0.9660, -0.8038],\n",
      "        [ 1.7398, -1.7401],\n",
      "        [ 2.4212, -2.5086],\n",
      "        [ 2.3841, -2.4650],\n",
      "        [ 1.9829, -2.0074],\n",
      "        [ 2.3280, -2.4010],\n",
      "        [ 1.8062, -1.8063],\n",
      "        [ 2.5330, -2.6375],\n",
      "        [ 2.5926, -2.7054],\n",
      "        [ 1.5990, -1.4970],\n",
      "        [ 1.7595, -1.7699],\n",
      "        [ 2.7760, -2.9163],\n",
      "        [ 1.5195, -1.4096],\n",
      "        [ 2.1562, -2.2154],\n",
      "        [ 2.6063, -2.7271],\n",
      "        [ 1.9017, -1.9027],\n",
      "        [ 1.7322, -1.7021],\n",
      "        [ 2.2603, -2.3215],\n",
      "        [ 2.4452, -2.5362],\n",
      "        [ 1.9082, -1.8968],\n",
      "        [ 1.2825, -1.1970],\n",
      "        [ 2.5375, -2.6421],\n",
      "        [ 2.6514, -2.7688],\n",
      "        [ 2.5415, -2.6465],\n",
      "        [ 1.8185, -1.8115],\n",
      "        [ 2.7947, -2.9154],\n",
      "        [ 2.6917, -2.8191],\n",
      "        [ 2.6078, -2.7227],\n",
      "        [ 2.2089, -2.2589],\n",
      "        [ 2.1965, -2.2497],\n",
      "        [ 2.2861, -2.3582],\n",
      "        [ 2.6107, -2.7271],\n",
      "        [ 1.7088, -1.6933],\n",
      "        [ 1.9745, -1.9937],\n",
      "        [ 2.5897, -2.7034],\n",
      "        [ 1.9281, -1.9382],\n",
      "        [ 1.4330, -1.3821],\n",
      "        [ 1.7311, -1.7161],\n",
      "        [ 2.5671, -2.6775],\n",
      "        [ 2.5918, -2.7049],\n",
      "        [ 1.7418, -1.7233],\n",
      "        [ 2.7368, -2.8721],\n",
      "        [ 1.8416, -1.8434],\n",
      "        [ 2.5680, -2.6776],\n",
      "        [ 2.1926, -2.2494],\n",
      "        [ 1.8646, -1.8729],\n",
      "        [ 2.2972, -2.3676],\n",
      "        [ 2.5450, -2.6520],\n",
      "        [ 2.5120, -2.6154],\n",
      "        [ 2.0656, -2.0990],\n",
      "        [ 2.3237, -2.3976],\n",
      "        [ 2.5292, -2.6323],\n",
      "        [ 1.8836, -1.9283],\n",
      "        [ 2.6544, -2.7774],\n",
      "        [ 2.5268, -2.6312],\n",
      "        [ 2.5285, -2.6322],\n",
      "        [ 1.9780, -1.9425],\n",
      "        [ 2.4860, -2.5812]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-f0aa39cc87b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'targets'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    images, labels = data['image'].to(device), data['targets'].to(device)\n",
    "    print(labels)\n",
    "    outputs = net(images)\n",
    "    print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
